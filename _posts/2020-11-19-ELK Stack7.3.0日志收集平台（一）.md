---
layout: post
title:  "ELK Stack7.3.0日志收集平台（一）"
categories: ELK-Stack平台
tags: elk 日志收集
author: Zk1an
---

* content
{:toc}
> 本篇内容主要讲：
>
> - elk stack起源简介
> - 本次演示搭建的环境配置

## 一、写在前面的话

- 准备部署前，**一定要和客户沟通ELK版本问题**，官网的版本更新速度飞快，两三个月就要一次迭代。提前沟通好，会节省返工的时间成本。
- 如果**着急交付，千万不要去啃官方文档**，虽是精而全，面面俱到，但是短暂的时间内根本无法消化，反而会影响交付，这种场景下推荐的方式是：**以成熟的搭建系列博客为主，文档为辅。**

## 二、elk stack简介  

“ELK”是三个开源项目的首字母缩写，这三个项目分别是：Elasticsearch、Logstash 和 Kibana。  

- elasticsearch 是一个搜索和分析引擎。  
- Logstash 是服务器端数据处理管道，能够同时从多个来源采集数据，转换数据，然后将数据发送到诸如 Elasticsearch 等“存储库”中。  

- Kibana 则可以让用户在 Elasticsearch 中使用图形和图表对数据进行可视化。
- Beats 轻量型的单一功能数据采集器，由于Logstash很耗性能，beats应运而生。  
然而ELK 这个名称又要变了，的确如此。把它叫做 BELK？BLEK？ELKB？当时的确有过继续沿用首字母缩写的想法。然而，扩展速度如此之快，一直采用首字母缩写的确不是长久之计。  
就这样，Elastic Stack 这个名字应运而生了！！！ 
和用户一直以来熟知并喜爱的开源产品一模一样，只是集成程度更高了，功能更加强大了，入门也更加容易了，而且可以带来无限可能。

## 三、数据流向架构图
该日志管理平台的架构图如下：
![202011192137elk](../uPic/%202020%2011%2019%2021%2037elk.png)

大致流程介绍：  
1、每个应用服务器上都安装Filebeat组件，由于Logstash在进行清洗和过滤数据的时候比较耗用系统资源，如果直接把Logstash和应用系统部署在一起，可能会影响应用系统的运行，所以日志采集组件基本都是由轻量级的Filebeat替代。  
2、Filebeat组件将收集到的日志发送到kafka消息中间件（也可以是redis等），Filebeat可以通过fields.app(自定义属性)设置当前收集日志属于哪个应用，通过fields.topic(自定义属性)设置当前收集日志发送给kafka的哪个主题。  
3、Logstash从Kafka消息队列中采集日志信息，通过input.Kafka输入流来采集不同主题的日志，然后发送到es集群，针对不同的应用创建不同的索引文件。  
4、通过Kibana管理平台进行日志的搜索、可视化分析，以及用户的创建及权限设置。  

## 四、环境说明  

| IP | SystemInfo | Roles |
| :-----: | :-----: | :----: |
| 172.10.132.92 | CentOs 7.8 | ES(master) 、Elastcisearch-head插件|
| 172.10.132.93 | CentOs 7.8 | ES(slave) |
| 172.10.132.94 | CentOs 7.8 | ES(slave) |
| 172.10.132.95 | CentOs 7.8 | Kafka、logstash、kibana |
| 172.10.132.96 | CentOs 7.8 | Kafka、logstash |
| 172.10.132.97 | CentOs 7.8 | Kafka、logstash |

本篇内容先到这里，从下一篇开始介绍各个组件的安装部署流程，其中把自己搭建过程中遇到的一些问题也会列举出来供大家参考，
如果搭建过程中遇到类似的问题，可以很快得到处理，避免走一些不必要的弯路。  
欢迎大家留言一起讨论，共同学习，一起进步!


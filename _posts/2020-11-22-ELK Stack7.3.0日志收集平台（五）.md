---

layout: post
title:  "ELK Stack7.3.0日志收集平台（五）"
categories: ELK-Stack平台
tags: elk 日志收集
author: Zk1an
---

* content
{:toc}
> 本篇内容主要讲：
>
> - 日志过滤清洗组件**Logstash**安装使用
> - Elasticsearch 索引文件可视化管理工具**Kibana**安装使用

## 一、Logstash组件安装使用

### 1.1、下载Logstash安装包

```shell
[root@host ~]# cd /usr/local/elkstack  
[root@host ~]# curl -L -O https://artifacts.elastic.co/downloads/logstash/logstash-7.3.0.tar.gz
```

### 1.2、解压

```shell
[root@host ~]# tar -zxvf logstash-7.3.0.tar.gz
```

### 1.3、logstash配置文件详解

#### 1.3.1、配置文件如何根据业务进行拆分？

配置文件一般存放于 logstash安装目录/config/目录中，我们可以在此目录新建一个conf.d文件夹，专门用于存放logstash的配置文件。在conf.d文件夹下，可以根据业务系统的不同，创建不同的conf文件，从而达到拆分配置文件的目的。**但是值得注意的是，配置文件中的filter模块、output模块必须采用if进行判断**。  

例如：conf.d目录下存放了order.conf、shop.conf，logstash启动后，不会先加载order.conf的input --> filter --> output，再加载shop.conf的input --> filter --> output，**而是这样加载的：order.conf、shop.conf的input --> order.conf、shop.conf的filter --> order.conf、shop.conf的output**，所以不加if去限制的话，order的日志不但会同时走order、shop的filter,而且最后的数据会output到两者的es中，导致所以的数据都被污染。  

${logstash_home}/config/conf.d/order.conf大致框架模型：

```properties
input {
    kafka {
      type: "order"
    ....
    }
}
filter {
  if ([type] == "order") {
    //执行过滤逻辑
  }
}
output {
    if [type] == "order" {
        elasticsearch {
          ...
          //发送数据给order的es索引下
        }
    }
}
```

${logstash_home}/config/conf.d/shop.conf大致框架模型：  

```properties
input {
    kafka {
      type: "shop"
    ....
    }
}
filter {
  if [type] == "shop" {
    //执行过滤逻辑
  }
}
output {
    if [type] == "shop" {
        elasticsearch {
          ...
          //发送数据给shop的es索引下
        }
    }
}
```

#### 1.3.2、配置文件中的模块详解

Logstash由三个组件构造成，分别是input、filter以及output。我们可以吧Logstash三个组件的工作流理解为：input收集数据，filter处理数据，output输出数据。

##### input组件

input 支持多种类型，如文件、数据库、Redis、filebeat、tcp等，由于本次对接了kafka和tcp，其他没涉及的请自行查阅。  

###### kafka

```properties
input {
    kafka {
         bootstrap_servers => "172.10.132.95:9092,172.10.132.96:9092,172.10.132.97:9092"
         topics => ["demo"]
         codec => json {
            charset => "UTF-8"
         }
         type => "demo"
         group_id => "logstash_grop"
         client_id => "kf_client_0"
         auto_offset_reset => "earliest"
    }
}
# bootstrap_servers 数据来源，这里表示kafka集群地址  
# topics 用于此业务消费的kafka集群主题，类型为数组  
# codec 定义数据编码，为必写配置，保证数据以json格式展示  
# type 自定义数据，唯一的作用就是 在当前配置文件的filter、output中参与if判断，执行不同的处理逻辑  
# group_id 使用者自己定义，多台logstash必须保证一致，用于保证多个logstash作为一个消费者，去消费kafka的topic  
# client_id 全局（所有配置文件）唯一，作为kafka客户端的标识  
# auto_offset_reset 表示当logstash的offset发送错误时，从头开始消费
```

###### tcp  

```properties
input {
    tcp {
        port => 8888
        type => "tcp-req"
    }
}
# port为监听的数据端口
```



##### filter组件

filter中有很多的组件，这块只介绍笔者使用到的部分，有别的需求请自行查询。

测试数据：

```json
{"message": "2020-12-01 18:08:32.163 [1333714590125293570] [XNIO-1 task-160] INFO  com.demo.common.aspect.LogRecordAspect -Content-Length:199"}
```

###### 1、grok

将整条message根据match进行匹配拆分  

```properties
filter {
grok {
   match => { "message" => "%{TIMESTAMP_ISO8601:logtime} \[%{GREEDYDATA:trace}\] \[%{GREEDYDATA:thread}\] %{WORD:level} %{GREEDYDATA:logInfo}"}
      }
}
```

结果：

```json
{
  "trace": "1333714590125293570",
  "level": "INFO",
  "thread": "XNIO-1 task-160",
  "logInfo": " com.demo.common.aspect.LogRecordAspect -Content-Length:199",
  "logtime": "2020-12-01 18:08:32.163"
}
```

###### 2、date

时间格式转换，并将转换后的值赋给@timestamp

```properties
date {
     match => ["logtime", "yyyy-MM-dd HH:mm:ss.SSS"]
     target => "@timestamp"
}
```

###### 3、mutate

计算插件，用于重写、添加、删除某个属性。  

下面的意思是，不存在trace的时候，添加一个值为“-”的属性。

```properties
if ![trace] {
          mutate {
                 add_field => {
                                "trace" => "-"
                 }
          }
}
```

下面的意思是，删除logtime属性。

```properties
 mutate {
     remove_field => ["logtime"]
}
```

下面的意思是，将logInfo以“.”进行拆分，并将拆分后数组的最后一个值，赋值给新字段logtype（这里只是对用法进行举例）。

```properties
mutate {
     split => ["logInfo","."]
     add_field => {
       "logtype" => "%{[logInfo][-1]}"
     }
}
```

下面的意思是，将logtype转换为全小写。

```properties
mutate {
     lowercase => ["logtype"]
}
```

下面的意思是，将message中的\\u003c替换为'<'。

```properties
mutate {
gsub => [ "message", "\\u003c", "<" ] 
}
```

下面的意思是，将数组转换为key:value类型。

```properties
mutate {
   rename => {"[log][0]" => "[log]"}
}
```

###### 4、geoip

此插件的作用是去解析地图可视化的需要的数据。

```properties
geoip {
   source => "ip"
   target => "geoip"
}
```

###### 5、xml

下面以解析oracle的xml日志进行举例说明。

测试数据如下：

```properties
<msg time='2020-11-25T17:48:02.457+08:00' org_id='oracle' comp_id='dfesdfe'
 client_id='' type='UNKNOWN' level='16'
 host_id='demo' host_addr='XXXXX' module=''
 pid='10000'>
 <txt>Archived Log entry 124378 added for thread 4 sequence 57217 ID 0x591fdd82 dest 1:
 </txt>
</msg>
```

解析的filter配置：

```properties
xml {
    source => message
    target =>"doc"
    xpath => [
    "/msg/@time","logdate",
    "/msg/@org_id","org_id",
    "/msg/@comp_id","comp_id",
    "/msg/@msg_id","msg_id",
    "/msg/@type","log_type",
    "/msg/@group","group",
    "/msg/@level","level",
    "/msg/@host_id","host_id",
    "/msg/@host_addr","host_addr",
    "/msg/txt/text()","log"
    ]
}
```

结果就不贴了，它会把xml中的数据都拿出来。

##### output组件

output比较简单，下面是示例以及说明。

```properties
elasticsearch {
           hosts => ["172.10.132.92:9200","172.10.132.93:9200","172.10.132.94:9200"]
           index => "demo-%{+YYYY.MM}"
}
 
# hosts是es集群的地址
# index为数据发送到es中的索引名称（%{+YYYY.MM}表示年、月时间后缀）
```

调试时需要打印结果的情况：  

```properties
stdout {
     codec => json
}
```

### 1.4、logstash启动

在logstash根目录下执行启动命令，可以先通过控制台标准输入、输出方式进行验证logstash是否正常启动。

```shell
bin/logstash -e 'input { stdin {}} output{stdout {codec=>rubydebug}}'

输入inputmsgtest

{
 "host" => "nodek8sworker",
 "@timestamp" => 2019-08-24T09:28:34.130Z,
 "message" => "inputmsgtest",
 "@version" => "1"
}
看到以上输出，logstash启动成功。
```

下面通过logstash配置文件启动。

```shell
/bin/logstash -f ./config/conf.d/

打印以下命令说明启动成功。
......
Successfully started Logstash API endpoint {:port=>9600}
```



## 二、可视化管理平台Kibana安装使用

### 2.1、下载kibana安装包

```shell
wget https://artifacts.elastic.co/downloads/kibana/kibana-7.3.0-linux-x86_64.tar.gz
```

### 2.2、解压

```shell
tar -zxvf kibana-7.3.0-linux-x86_64.tar.gz
```

### 2.3、启动kibana

切换至elkstack用户(可参考第二篇文章创建授权)，也可使用 --allow-root 参数允许root用户启动。

```shell
bin/kibana --allow-root

日志打印出
Status changed from yellow to green - Ready
启动成功！
```

### 2.4、访问

http://172.10.132.95:5601/